{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working, first 650 epochs lr = 1e-4, 650-1450 lr = 5e-5\n",
    "# training took 24h on a P100 on kaggle, the code was not that optimized and a GAN can't be compiled.\n",
    "# had trouble with model colapse and had to lower the batch size and keep precision high\n",
    "# using lighting AI resulted in model collapse every time, I had to revert to pure pytorch for this one.\n",
    "# used the WGAN architecure\n",
    "# I am not proud of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from natsort import natsorted\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import wandb\n",
    "\n",
    "import datetime\n",
    "\n",
    "# cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    print('cuda is available')\n",
    "    # get the number of GPUs\n",
    "    print('number of GPUs:', torch.cuda.device_count())\n",
    "    # get the name of the GPU\n",
    "    print('name of the GPU:', torch.cuda.get_device_name(0))\n",
    "    # get the current device\n",
    "    print('current device:', torch.cuda.current_device())\n",
    "\n",
    "    cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"###\"\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"JANGAN4\",\n",
    "\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.000005,\n",
    "    \"architecture\": \"WGAN\",\n",
    "    \"dataset\": \"FFHQ\",\n",
    "    \"epochs\": 3000,\n",
    "    }\n",
    ")\n",
    "# wandb.login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 3000\n",
    "batch_size = 32\n",
    "lr = 0.000005\n",
    "n_cpu = os.cpu_count()\n",
    "latent_dim = 128\n",
    "img_size = 64\n",
    "channels = 3\n",
    "n_critic = 5\n",
    "clip_value = 0.1\n",
    "sample_interval = 400\n",
    "\n",
    "img_shape = (channels, img_size, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.shape[0], *img_shape)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(img_size),\n",
    "    transforms.CenterCrop(img_size),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "dataset = CustomImageDataset(img_dir=\"/kaggle/input/ffhq-128-70k\", transform=transform)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(generator, discriminator, optimizer_G, optimizer_D, epoch, loss_G, loss_D, save_dir):\n",
    "    # Create checkpoint directory if it doesn't exist\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'generator_state_dict': generator.state_dict(),\n",
    "        'discriminator_state_dict': discriminator.state_dict(),\n",
    "        'optimizer_G_state_dict': optimizer_G.state_dict(),\n",
    "        'optimizer_D_state_dict': optimizer_D.state_dict(),\n",
    "        'loss_G': loss_G,\n",
    "        'loss_D': loss_D\n",
    "    }\n",
    "    \n",
    "    # Save with timestamp and epoch number\n",
    "    timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    path = os.path.join(save_dir, f'checkpoint_epoch_{epoch}_{timestamp}.pth')\n",
    "    torch.save(checkpoint, path)\n",
    "    \n",
    "    return path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(path, generator, discriminator, optimizer_G, optimizer_D):\n",
    "    checkpoint = torch.load(path)\n",
    "    \n",
    "    # Load model states\n",
    "    generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "    \n",
    "    # Load optimizer states, uncomment if using a lr scheduler\n",
    "\n",
    "    # optimizer_G.load_state_dict(checkpoint['optimizer_G_state_dict'])\n",
    "    # optimizer_D.load_state_dict(checkpoint['optimizer_D_state_dict'])\n",
    "    \n",
    "    # Return other training info\n",
    "    return checkpoint['epoch'], checkpoint['loss_G'], checkpoint['loss_D']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "\n",
    "# if resuming training \n",
    "# generator.load_state_dict(torch.load(\"2024-11-05_14-41-32/50G.pth\", weights_only=True))\n",
    "# discriminator.load_state_dict(torch.load(\"2024-11-05_14-41-32/50D.pth\", weights_only=False))\n",
    "\n",
    "if cuda:\n",
    "    generator.cuda()\n",
    "    discriminator.cuda()\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "# scheduler_G = lr_scheduler.LinearLR(optimizer_G, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "# scheduler_D = lr_scheduler.LinearLR(optimizer_D, start_factor=1.0, end_factor=0.3, total_iters=10)\n",
    "\n",
    "# might be possible to lower the precision but I chose to have more stability.\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "torch.set_float32_matmul_precision(\"highest\")\n",
    "# ----------\n",
    "#  Training\n",
    "# ----------\n",
    "\n",
    "start_epoch, loss_G, loss_D = load_checkpoint(\n",
    "    '/kaggle/input/124/pytorch/default/1/checkpoint_epoch_650_20241231_042627.pth',\n",
    "    generator,\n",
    "    discriminator,\n",
    "    optimizer_G,\n",
    "    optimizer_D\n",
    ")\n",
    "\n",
    "batches_done = 0\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    for i, imgs in enumerate(dataloader):\n",
    "\n",
    "        # if epoch % 190 == 0:\n",
    "        #     torch.save(generator.state_dict(), f\"{epoch}\" + \"G.pth\")\n",
    "        #     torch.save(discriminator.state_dict(), f\"{epoch}\"+ \"D.pth\")\n",
    "\n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(imgs.type(Tensor))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Sample noise as generator input\n",
    "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
    "\n",
    "        # Generate a batch of images\n",
    "        fake_imgs = generator(z).detach()\n",
    "        # Adversarial loss\n",
    "        loss_D = -torch.mean(discriminator(real_imgs)) + torch.mean(discriminator(fake_imgs))\n",
    "\n",
    "        loss_D.backward()\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # Clip weights of discriminator\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-clip_value, clip_value)\n",
    "        # print(lr)\n",
    "        # scheduler_G.step()\n",
    "\n",
    "        # Train the generator every n_critic iterations\n",
    "        if i % n_critic == 0:\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            optimizer_G.zero_grad()\n",
    "\n",
    "            # Generate a batch of images\n",
    "            gen_imgs = generator(z)\n",
    "            # Adversarial loss\n",
    "            loss_G = -torch.mean(discriminator(gen_imgs))\n",
    "\n",
    "            loss_G.backward()\n",
    "            optimizer_G.step()\n",
    "\n",
    "            # scheduler_D.step()\n",
    "\n",
    "            print(\n",
    "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [Total loss: %f]\"\n",
    "                % (epoch, n_epochs, batches_done % len(dataloader), len(dataloader), loss_D.item(), loss_G.item(), loss_D.item() + loss_G.item())\n",
    "            )\n",
    "            \n",
    "\n",
    "        # if batches_done % sample_interval == 0:\n",
    "        #     # #save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)\n",
    "        #     # save_image(gen_imgs[:25], f\"{now_str}/{batches_done}.png\", nrow=5, normalize=True)\n",
    "        #     wandb.log({\"examples\": [wandb.Image(image) for image in gen_imgs[:15]]})\n",
    "\n",
    "        wandb.log({\"epoch\": epoch+650, \"loss_D\": loss_D, \"loss_G\": loss_G, \"total_loss\": loss_G + loss_D})\n",
    "        batches_done += 1\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        wandb.log({\"examples\": [wandb.Image(image) for image in gen_imgs[:10]]})\n",
    "    # Model saving\n",
    "    if epoch % 50 == 0:\n",
    "        save_path = save_checkpoint(\n",
    "            generator,\n",
    "            discriminator,\n",
    "            optimizer_G,\n",
    "            optimizer_D,\n",
    "            epoch+650,\n",
    "            loss_G.item(),\n",
    "            loss_D.item(),\n",
    "            save_dir='/kaggle/working/checkpoints'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
