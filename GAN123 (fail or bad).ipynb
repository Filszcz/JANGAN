{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 16 images and grid in generated_images\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import lightning as L\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import os\n",
    "\n",
    "class Generator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        self.init_size = 64 // 4\n",
    "        self.latent_dim = 512\n",
    "\n",
    "        self.l1 = torch.nn.Sequential(torch.nn.Linear(self.latent_dim, 128 * self.init_size ** 2))\n",
    "\n",
    "        self.conv_blocks = torch.nn.Sequential(\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            torch.nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(128, 0.8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Upsample(scale_factor=2),\n",
    "            torch.nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            torch.nn.BatchNorm2d(64, 0.8),\n",
    "            torch.nn.LeakyReLU(0.2, inplace=True),\n",
    "            torch.nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
    "            torch.nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class Discriminator(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [torch.nn.Conv2d(in_filters, out_filters, 3, 2, 1), \n",
    "                    torch.nn.LeakyReLU(0.2, inplace=True), \n",
    "                    torch.nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(torch.nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "\n",
    "        self.model = torch.nn.Sequential(\n",
    "            *discriminator_block(3, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "\n",
    "        ds_size = 64 // 2 ** 4\n",
    "        self.adv_layer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(128 * ds_size ** 2, 1), \n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        return validity\n",
    "\n",
    "class GAN(L.LightningModule):\n",
    "    def __init__(\n",
    "            self,\n",
    "            img_size: int = 64,\n",
    "            latent_dim: int = 512,\n",
    "            lr: float = 1e-5,\n",
    "            b1: float = 0.5,\n",
    "            b2: float = 0.999,\n",
    "            n_critic: int = 5\n",
    "            ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.automatic_optimization = False\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        self.generator = Generator()\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        self.criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "def generate_images(\n",
    "    num_images=16, \n",
    "    output_dir=\"generated_images\", \n",
    "    checkpoint_path=\"Weights/WGANGP_MNIST_final/epoch=570-step=2498696.ckpt\",\n",
    "    grid_size=(4, 4)  # Default 4x4 grid\n",
    "):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load the model\n",
    "    model = GAN.load_from_checkpoint(checkpoint_path)\n",
    "    model.eval()\n",
    "    \n",
    "    # Move model to GPU if available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Generate images\n",
    "    with torch.no_grad():\n",
    "        # Create random noise vectors\n",
    "        z = torch.randn(num_images, model.latent_dim).to(device)\n",
    "        \n",
    "        # Generate images\n",
    "        generated_images = model(z)\n",
    "        \n",
    "        # Denormalize the images using the same values as in training\n",
    "        denorm = transforms.Normalize(\n",
    "            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225],\n",
    "            std=[1/0.229, 1/0.224, 1/0.225]\n",
    "        )\n",
    "        \n",
    "        # Denormalize all images\n",
    "        denormalized_images = torch.stack([denorm(img) for img in generated_images])\n",
    "        \n",
    "        # Create and save individual images\n",
    "        for i, img_tensor in enumerate(denormalized_images):\n",
    "            # Convert to PIL image and save\n",
    "            img_array = (img_tensor * 255).clamp(0, 255).permute(1, 2, 0).cpu().numpy().astype('uint8')\n",
    "            img = Image.fromarray(img_array)\n",
    "            # img.save(os.path.join(output_dir, f'generated_image_{i}.png'))\n",
    "        \n",
    "        # Create and save grid\n",
    "        grid = vutils.make_grid(\n",
    "            denormalized_images, \n",
    "            nrow=grid_size[0],\n",
    "            padding=2, \n",
    "            normalize=False\n",
    "        )\n",
    "        \n",
    "        # Convert grid to image and save\n",
    "        grid_array = (grid.permute(1, 2, 0) * 255).clamp(0, 255).cpu().numpy().astype('uint8')\n",
    "        grid_image = Image.fromarray(grid_array)\n",
    "        grid_image.save(os.path.join(output_dir, 'generated_grid.png'))\n",
    "            \n",
    "    print(f\"Generated {num_images} images and grid in {output_dir}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate 16 images in a 4x4 grid\n",
    "    generate_images(\n",
    "        num_images=16,\n",
    "        output_dir=\"generated_images\",\n",
    "        checkpoint_path=\"Weights/epoch=570-step=2498696 (1).ckpt\",\n",
    "        grid_size=(4, 4)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
