{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "#47080269e7b1b5a51a89830cb24c495498237e77\n",
    "\n",
    "wandb.login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=\"JANGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-04_18-06-55\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(now_str)\n",
    "\n",
    "# make a new folder with the name now_str\n",
    "import os\n",
    "os.makedirs(now_str, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m     13\u001b[0m torch\u001b[38;5;241m.\u001b[39mset_float32_matmul_precision(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedium\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43;01mCustomImageDataset\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_dir\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimg_dir\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mCustomImageDataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomImageDataset\u001b[39;00m(Dataset):\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img_dir\u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marchive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, transform\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_dir \u001b[38;5;241m=\u001b[39m img_dir\n\u001b[1;32m     18\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m transform\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"archive\", img_size: int = 128, batch_size: int = 256, num_workers: int = 8):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.CenterCrop(self.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = CustomImageDataset(img_dir=self.data_dir, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, latent_dim, img_shape):\n",
    "#         super().__init__()\n",
    "#         self.img_shape = img_shape\n",
    "\n",
    "#         def block(in_feat, out_feat, normalize=True):\n",
    "#             layers = [nn.Linear(in_feat, out_feat)]\n",
    "#             if normalize:\n",
    "#                 layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "#             layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "#             return layers\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             *block(latent_dim, 128, normalize=False),\n",
    "#             *block(128, 256),\n",
    "#             *block(256, 128),\n",
    "#             nn.Linear(128, int(np.prod(img_shape))),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         img = self.model(z)\n",
    "#         img = img.view(img.size(0), *self.img_shape)\n",
    "#         return img\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.01, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.model = nn.Sequential(\n",
    "        #     nn.Linear(int(np.prod(img_shape)), 128),\n",
    "        #     nn.LeakyReLU(0.2, inplace=True),\n",
    "        #     nn.Linear(128, 256),\n",
    "        #     nn.LeakyReLU(0.2, inplace=True),\n",
    "        #     nn.Linear(256, 1),\n",
    "        # )\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        width,\n",
    "        height,\n",
    "        latent_dim: int = 128,\n",
    "        lr: float = 0.01,\n",
    "        n_critic: int = 5,\n",
    "        clip_value: float = 0.01,\n",
    "        sample_interval: int = 400,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        # networks\n",
    "        data_shape = (channels, width, height)\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim, img_shape=data_shape)\n",
    "        self.discriminator = Discriminator(img_shape=data_shape)\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs = batch\n",
    "\n",
    "        optimizer_g, optimizer_d = self.optimizers()\n",
    "        \n",
    "        # train discriminator\n",
    "        self.toggle_optimizer(optimizer_d)\n",
    "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim, device=self.device)\n",
    "        fake_imgs = self(z).detach()\n",
    "\n",
    "        real_validity = self.discriminator(imgs)\n",
    "        fake_validity = self.discriminator(fake_imgs)\n",
    "\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "        self.log(\"d_loss\", d_loss, prog_bar=False)\n",
    "        self.manual_backward(d_loss)\n",
    "        optimizer_d.step()\n",
    "        self.log(\"lr\", self.hparams.lr)\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # Clip weights of discriminator\n",
    "        for p in self.discriminator.parameters():\n",
    "            p.data.clamp_(-self.hparams.clip_value, self.hparams.clip_value)\n",
    "\n",
    "        self.untoggle_optimizer(optimizer_d)\n",
    "\n",
    "        # train generator\n",
    "        if batch_idx % self.hparams.n_critic == 0:\n",
    "            self.toggle_optimizer(optimizer_g)\n",
    "            z = torch.randn(imgs.shape[0], self.hparams.latent_dim, device=self.device)\n",
    "            gen_imgs = self(z)\n",
    "            gen_validity = self.discriminator(gen_imgs)\n",
    "            g_loss = -torch.mean(gen_validity)\n",
    "            self.log(\"g_loss\", g_loss, prog_bar=False)\n",
    "            self.log(\"total_loss\", g_loss + d_loss, prog_bar=False)\n",
    "            self.manual_backward(g_loss)\n",
    "            optimizer_g.step()\n",
    "            optimizer_g.zero_grad()\n",
    "            self.untoggle_optimizer(optimizer_g)\n",
    "\n",
    "        if self.global_step % self.hparams.sample_interval == 0:\n",
    "            self.sample_images()\n",
    "        # self.log(\"lr\", self.lr)\n",
    "\n",
    "    def sample_images(self):\n",
    "        z = torch.randn(25, self.hparams.latent_dim, device=self.device)\n",
    "        gen_imgs = self(z)\n",
    "        save_image(gen_imgs, f\"{now_str}/{self.global_step}.png\", nrow=5, normalize=True)\n",
    "        wandb.log({\"examples\": [wandb.Image(image) for image in gen_imgs]})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=0.0001)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=0.0001)\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "# Set up data\n",
    "dm = CustomDataModule()\n",
    "cd = CustomImageDataset()\n",
    "\n",
    "# Set up model\n",
    "model = GAN(\n",
    "    channels=3,\n",
    "    width=128,\n",
    "    height=128,\n",
    "    latent_dim=128,\n",
    "    lr=0.0001,\n",
    "    n_critic=5,\n",
    "    clip_value=0.01,\n",
    "    sample_interval=400\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=1000,\n",
    "    logger=wandb_logger,\n",
    "    precision=\"bf16\",\n",
    "    default_root_dir={now_str}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>d_loss</td><td>▄▃▂▁▁▂▁▁▁▂▁▇▆██▇▇▆▆▇▇▇▆██▇▇▇▇▇▆▆▆▆▆▇▇▇▇▇</td></tr><tr><td>epoch</td><td>▁▂▂▂▂▃▃▃▃▁▁▁▁▂▂▂▂▃▃▃▃▃▃▄▄▄▅▆▆▆▆▆▆▆▆▇▇▇██</td></tr><tr><td>g_loss</td><td>█████▇▇██████▂▃▁▁▁▂▁▃▃▃▁▂▄▃▁▃▂▂▂▃▃▃▂▃▃▂▂</td></tr><tr><td>lr</td><td>██████████▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>██▇▁▄▄▅▄▅▅▄▄▄▅▇▄▆▆▄▄▄▄▅▅▄▄▅▄▄▆▇▆▇▅▄▄▄▄▄▄</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▃▁▁▂▂▂▂▂▂▃▃▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇███</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>d_loss</td><td>-0.57031</td></tr><tr><td>epoch</td><td>17</td></tr><tr><td>g_loss</td><td>-0.41992</td></tr><tr><td>lr</td><td>1e-05</td></tr><tr><td>total_loss</td><td>-1</td></tr><tr><td>trainer/global_step</td><td>4849</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vocal-dust-17</strong> at: <a href='https://wandb.ai/filip-szczepanski/JANGAN/runs/r9qb1kzg' target=\"_blank\">https://wandb.ai/filip-szczepanski/JANGAN/runs/r9qb1kzg</a><br/> View project at: <a href='https://wandb.ai/filip-szczepanski/JANGAN' target=\"_blank\">https://wandb.ai/filip-szczepanski/JANGAN</a><br/>Synced 7 W&B file(s), 0 media file(s), 8 artifact file(s) and 400 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241103_160912-r9qb1kzg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
