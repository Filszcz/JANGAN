{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "#47080269e7b1b5a51a89830cb24c495498237e77\n",
    "\n",
    "wandb.login()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(project=\"JANGAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-01_11-45-32\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "now_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "print(now_str)\n",
    "\n",
    "# make a new folder with the name now_str\n",
    "import os\n",
    "os.makedirs(now_str, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fil/miniconda3/envs/ML/lib/python3.12/site-packages/lightning_fabric/connector.py:571: `precision=bf16` is supported for historical reasons but its usage is discouraged. Please set your precision to bf16-mixed instead!\n",
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/fil/miniconda3/envs/ML/lib/python3.12/site-packages/lightning/pytorch/loggers/wandb.py:396: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type          | Params | Mode  | In sizes | Out sizes       \n",
      "--------------------------------------------------------------------------------------\n",
      "0 | generator     | Generator     | 51.1 M | train | [2, 128] | [2, 3, 128, 128]\n",
      "1 | discriminator | Discriminator | 25.3 M | train | ?        | ?               \n",
      "--------------------------------------------------------------------------------------\n",
      "76.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "76.4 M    Total params\n",
      "305.555   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 517:  18%|█▊        | 50/274 [00:02<00:11, 20.34it/s, v_num=k5ko] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fil/miniconda3/envs/ML/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:54: Detected KeyboardInterrupt, attempting graceful shutdown...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.images = [f for f in os.listdir(img_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image\n",
    "\n",
    "class CustomDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, data_dir: str = \"archive\", img_size: int = 128, batch_size: int = 256, num_workers: int = 8):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize(self.img_size),\n",
    "            transforms.CenterCrop(self.img_size),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "        ])\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.dataset = CustomImageDataset(img_dir=self.data_dir, transform=self.transform)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "# class Generator(nn.Module):\n",
    "#     def __init__(self, latent_dim, img_shape):\n",
    "#         super().__init__()\n",
    "#         self.img_shape = img_shape\n",
    "\n",
    "#         def block(in_feat, out_feat, normalize=True):\n",
    "#             layers = [nn.Linear(in_feat, out_feat)]\n",
    "#             if normalize:\n",
    "#                 layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "#             layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "#             return layers\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             *block(latent_dim, 128, normalize=False),\n",
    "#             *block(128, 256),\n",
    "#             *block(256, 128),\n",
    "#             nn.Linear(128, int(np.prod(img_shape))),\n",
    "#             nn.Tanh()\n",
    "#         )\n",
    "\n",
    "#     def forward(self, z):\n",
    "#         img = self.model(z)\n",
    "#         img = img.view(img.size(0), *self.img_shape)\n",
    "#         return img\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super().__init__()\n",
    "        self.img_shape = img_shape\n",
    "\n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.01, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.model = nn.Sequential(\n",
    "        #     nn.Linear(int(np.prod(img_shape)), 128),\n",
    "        #     nn.LeakyReLU(0.2, inplace=True),\n",
    "        #     nn.Linear(128, 256),\n",
    "        #     nn.LeakyReLU(0.2, inplace=True),\n",
    "        #     nn.Linear(256, 1),\n",
    "        # )\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.shape[0], -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "class GAN(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        channels,\n",
    "        width,\n",
    "        height,\n",
    "        latent_dim: int = 128,\n",
    "        lr: float = 0.01,\n",
    "        n_critic: int = 5,\n",
    "        clip_value: float = 0.01,\n",
    "        sample_interval: int = 400,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.automatic_optimization = False\n",
    "\n",
    "        # networks\n",
    "        data_shape = (channels, width, height)\n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim, img_shape=data_shape)\n",
    "        self.discriminator = Discriminator(img_shape=data_shape)\n",
    "\n",
    "        self.validation_z = torch.randn(8, self.hparams.latent_dim)\n",
    "        self.example_input_array = torch.zeros(2, self.hparams.latent_dim)\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.generator(z)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs = batch\n",
    "\n",
    "        optimizer_g, optimizer_d = self.optimizers()\n",
    "        \n",
    "        # train discriminator\n",
    "        self.toggle_optimizer(optimizer_d)\n",
    "        z = torch.randn(imgs.shape[0], self.hparams.latent_dim, device=self.device)\n",
    "        fake_imgs = self(z).detach()\n",
    "\n",
    "        real_validity = self.discriminator(imgs)\n",
    "        fake_validity = self.discriminator(fake_imgs)\n",
    "\n",
    "        d_loss = -torch.mean(real_validity) + torch.mean(fake_validity)\n",
    "        self.log(\"d_loss\", d_loss, prog_bar=False)\n",
    "        self.manual_backward(d_loss)\n",
    "        optimizer_d.step()\n",
    "        self.log(\"lr\", self.hparams.lr)\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # Clip weights of discriminator\n",
    "        for p in self.discriminator.parameters():\n",
    "            p.data.clamp_(-self.hparams.clip_value, self.hparams.clip_value)\n",
    "\n",
    "        self.untoggle_optimizer(optimizer_d)\n",
    "\n",
    "        # train generator\n",
    "        if batch_idx % self.hparams.n_critic == 0:\n",
    "            self.toggle_optimizer(optimizer_g)\n",
    "            z = torch.randn(imgs.shape[0], self.hparams.latent_dim, device=self.device)\n",
    "            gen_imgs = self(z)\n",
    "            gen_validity = self.discriminator(gen_imgs)\n",
    "            g_loss = -torch.mean(gen_validity)\n",
    "            self.log(\"g_loss\", g_loss, prog_bar=False)\n",
    "            self.log(\"total_loss\", g_loss + d_loss, prog_bar=False)\n",
    "            self.manual_backward(g_loss)\n",
    "            optimizer_g.step()\n",
    "            optimizer_g.zero_grad()\n",
    "            self.untoggle_optimizer(optimizer_g)\n",
    "\n",
    "        if self.global_step % self.hparams.sample_interval == 0:\n",
    "            self.sample_images()\n",
    "        # self.log(\"lr\", self.lr)\n",
    "\n",
    "    def sample_images(self):\n",
    "        z = torch.randn(25, self.hparams.latent_dim, device=self.device)\n",
    "        gen_imgs = self(z)\n",
    "        save_image(gen_imgs, f\"{now_str}/{self.global_step}.png\", nrow=5, normalize=True)\n",
    "        wandb.log({\"examples\": [wandb.Image(image) for image in gen_imgs]})\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        opt_g = torch.optim.Adam(self.generator.parameters(), lr=0.0001)\n",
    "        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=0.0001)\n",
    "        return [opt_g, opt_d], []\n",
    "\n",
    "# Set up data\n",
    "dm = CustomDataModule()\n",
    "\n",
    "# Set up model\n",
    "model = GAN(\n",
    "    channels=3,\n",
    "    width=128,\n",
    "    height=128,\n",
    "    latent_dim=128,\n",
    "    lr=0.0001,\n",
    "    n_critic=5,\n",
    "    clip_value=0.01,\n",
    "    sample_interval=400\n",
    ")\n",
    "\n",
    "# Set up trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,\n",
    "    max_epochs=1000,\n",
    "    logger=wandb_logger,\n",
    "    precision=\"bf16\",\n",
    "    default_root_dir={now_str}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.fit(model, dm)\n",
    "\n",
    "# save the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>d_loss</td><td>▁▂▄▅▃▁▂▁▅▇▇▃▂▄▄▂▃▂▄▄▂█▅▁▁▄▆▆▃▁▃▅▂▂▄▄▇▅▃▂</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇███████</td></tr><tr><td>g_loss</td><td>▆█▆█▇▇▆▆▇▁▆▇▃▇█▇██▇▅██▇██▆▅▇▅▆▆██▆█▅▆▇▃▃</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>total_loss</td><td>▅▃▃▅▅▅▅▆▃▆▃▅▄▅█▅▃▅▄▅▄▄▃▃▅▃▄▃▅▃▃▅▅▃▁▅▃▃▄▃</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▆▆▆▆▆▆▇▇▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>d_loss</td><td>-0.87891</td></tr><tr><td>epoch</td><td>517</td></tr><tr><td>g_loss</td><td>-0.1001</td></tr><tr><td>lr</td><td>0.0001</td></tr><tr><td>total_loss</td><td>-0.99219</td></tr><tr><td>trainer/global_step</td><td>141699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">resplendent-offering-12</strong> at: <a href='https://wandb.ai/filip-szczepanski/JANGAN/runs/pgkbk5ko' target=\"_blank\">https://wandb.ai/filip-szczepanski/JANGAN/runs/pgkbk5ko</a><br/> View project at: <a href='https://wandb.ai/filip-szczepanski/JANGAN' target=\"_blank\">https://wandb.ai/filip-szczepanski/JANGAN</a><br/>Synced 5 W&B file(s), 0 media file(s), 10 artifact file(s) and 8900 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241101_114508-pgkbk5ko/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
